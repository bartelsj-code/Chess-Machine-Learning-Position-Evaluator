# -*- coding: utf-8 -*-
"""chess_heuristic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13FPS44XwHwHpjqNkywkudj6hITWyYNte
"""

from google.colab import drive
drive.mount('/content/drive')

FOLDERNAME = 'ML_Final_Project♙'
assert FOLDERNAME is not None, "[!] Enter the foldername."

import sys
sys.path.append('/content/drive/Shareddrives/{}'.format(FOLDERNAME))

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomFlip, RandomRotation
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense
from tensorflow.keras.losses import SparseCategoricalCrossentropy
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import math

tf.test.gpu_device_name()

data_size = 100000

# #load even data
# positions_filepath = 'drive/Shareddrives/ML_Final_Project♙/even_data/positions.npy'
# metadata_filepath = 'drive/Shareddrives/ML_Final_Project♙/even_data/metadata.npy'
# labels_filepath = 'drive/Shareddrives/ML_Final_Project♙/even_data/results_Y.npy'
# positions_even = np.load(positions_filepath)[:data_size]
# metadata_even = np.load(metadata_filepath)[:data_size]
# labels_even = np.load(labels_filepath)[:data_size]
# print(np.shape(positions_even))
# print(np.shape(metadata_even))
# print(np.shape(labels_even))

#load natural dat
positions_filepath = 'drive/Shareddrives/ML_Final_Project♙/uneven_data/positions.npy'
metadata_filepath = 'drive/Shareddrives/ML_Final_Project♙/uneven_data/metadata.npy'
labels_filepath = 'drive/Shareddrives/ML_Final_Project♙/uneven_data/results_Y.npy'
positions_natural = np.load(positions_filepath)[:data_size]
metadata_natural = np.load(metadata_filepath)[:data_size]
labels_natural = np.load(labels_filepath)[:data_size]
print(np.shape(positions_natural))
print(np.shape(metadata_natural))
print(np.shape(labels_natural))

def get_ratios(r):
    white_total = 0
    black_total = 0
    draw_total = 0
    total = len(r)
    for i in range(total):
        res = r[i]
        if res == 0:
            draw_total += 1
        if res == -1:
            black_total += 1
        if res == 1:
            white_total += 1
    return white_total, black_total, draw_total, total

# white_total, black_total, draw_total, total = get_ratios(labels_even)
# print("even data result ratios:\n\t white wins: {}       black wins: {}      draw: {}".format(white_total/total, black_total/total, draw_total/total))

white_total, black_total, draw_total, total = get_ratios(labels_natural)
print("natural data result ratios:\n\t white wins: {}       black wins: {}      draw: {}".format(white_total/total, black_total/total, draw_total/total))

spread_factor = 0.7
#Loss functions
def sig_loss(y_true, y_hat):
    y_true = float(y_true)
    sigged_y = (2/(1+tf.math.exp(-y_hat*spread_factor)))-1
    loss = tf.math.abs(y_true-sigged_y)
    return loss

def exp_loss(y_true, y_hat):
    y_true = float(y_true)
    wins_component = tf.math.abs(y_true) * tf.math.exp(-spread_factor*y_true*y_hat)
    draws_component = (1-tf.math.abs(y_true))*spread_factor*y_hat**2
    loss = wins_component + draws_component
    return loss

def correctness_sharp(y_true, y_hat):
    y_true = float(y_true)
    interpretation = tf.math.round(tf.math.minimum(tf.math.maximum(y_hat, -1),1))
    correctness = tf.math.maximum(1-tf.math.abs(y_true-interpretation),0)
    return correctness

def correctness_smooth(y_true, y_hat):
    y_true = float(y_true)
    draws_part = (1-tf.math.abs(y_true)) * tf.math.exp(-y_hat**2)
    wins_part = tf.math.abs(y_true)/(1+tf.math.exp(-y_true * 3 * (y_hat-0.5*y_true)))
    interpretation = draws_part + wins_part
    return interpretation

def make_model(name_string,
               convolution_list = [],
               raw_position_nn = [],
               pre_injection_nn = [],
               primary_nn = [],
               metadata_injection = "primaryNN",
               loss_func = exp_loss):

    position_input = keras.layers.Input(shape=(8,8,12))
    metadata_input = keras.layers.Input(shape=(7,))
    does_convolutions = (len(convolution_list) > 0)
    does_raw_position_nn = (len(raw_position_nn) > 0)
    does_pre_injection_nn = (len(pre_injection_nn) > 0)
    does_primary_nn = (len(primary_nn) > 0)

    if not(does_raw_position_nn or does_convolutions):
        raise Exception("Does not handle positional data")
        sys.exit(1)

    if not(does_raw_position_nn or does_primary_nn):
        raise Exception("Needs at least one neural network")
        sys.exit(1)

    if does_convolutions and not does_primary_nn:
        raise Exception("Needs primary nn to use convolutions")
        sys.exit(1)

    if not does_primary_nn and metadata_injection != "rawNN":
        raise Exception("Does not handle metadata")
        sys.exit(1)


    #possible metadata injection points
    injection_options = ["primaryNN"]
    if does_raw_position_nn:
        injection_options.append("rawNN")

    if metadata_injection not in injection_options:
        raise Exception("invalid metadata injection")
        sys.exit(1)


    #Position Convolutions:
    if does_convolutions:
        flattened_activation_map_list = []
        for filter_parameters in convolution_list:
            activation_map = keras.layers.Conv2D(filters = filter_parameters[0],
                                                 kernel_size = filter_parameters[1],
                                                 activation = 'relu',
                                                 padding = 'valid')(position_input)

            flattened_activation_map = keras.layers.Flatten()(activation_map)
            flattened_activation_map_list.append(flattened_activation_map)
        convolved_data = keras.layers.Concatenate(axis = 1)(flattened_activation_map_list)

    #Raw Position Neural Network
    if does_raw_position_nn:
        raw_position_flat = keras.layers.Flatten()(position_input)

        #inject metadata into raw
        if metadata_injection == 'rawNN':
            raw_position_flat = keras.layers.Concatenate(axis = 1)([metadata_input, raw_position_flat])

        #make denses raw
        raw_nn_layers = []
        layer1 = keras.layers.Dense(raw_position_nn[0],
                                    activation = keras.activations.relu,
                                    use_bias = True)(raw_position_flat)
        raw_nn_layers.append(layer1)
        i = 1
        while len(raw_nn_layers) < len(raw_position_nn):
            layer = keras.layers.Dense(raw_position_nn[i],
                                       activation = keras.activations.relu,
                                       use_bias = True)(raw_nn_layers[i-1])
            raw_nn_layers.append(layer)
            i += 1

    #define most_recent_layer for future layers
    if does_convolutions:
        if does_raw_position_nn:
            most_recent_layer = keras.layers.Concatenate(axis = 1)([convolved_data, raw_nn_layers[-1]])
        else:
            most_recent_layer = convolved_data
    else:
      #does only raw NN
        most_recent_layer = raw_nn_layers[-1]

    #primary_nn
    if does_primary_nn:
        if does_pre_injection_nn:
            #if metadata is added partway into the network
            pre_injection_nn_layers = []
            layer1 = keras.layers.Dense(pre_injection_nn[0],
                                        activation = keras.activations.relu,
                                        use_bias = True)(most_recent_layer)
            pre_injection_nn_layers.append(layer1)
            i = 1
            while len(pre_injection_nn_layers) < len(pre_injection_nn):
                layer = keras.layers.Dense(pre_injection_nn[i],
                                           activation = keras.activations.relu,
                                           use_bias = True)(pre_injection_nn_layers[i-1])
                pre_injection_nn_layers.append(layer)
                i += 1
            #set most_recent_layer for merging
            most_recent_layer = pre_injection_nn_layers[-1]

        if metadata_injection == "primaryNN":
            #merge if injecting in primary
            most_recent_layer = keras.layers.Concatenate(axis = 1)([most_recent_layer, metadata_input])

        #make primary (post-injection) layers
        primary_nn_layers = []
        layer1 = keras.layers.Dense(primary_nn[0],
                                    activation = keras.activations.sigmoid,
                                    use_bias = True)(most_recent_layer)
        primary_nn_layers.append(layer1)
        i = 1
        while len(primary_nn_layers) < len(primary_nn):
            layer = keras.layers.Dense(primary_nn[i],
                                       activation = keras.activations.sigmoid,
                                       use_bias = True )(primary_nn_layers[i-1])
            primary_nn_layers.append(layer)
            i += 1
        most_recent_layer = primary_nn_layers[-1]

    #create output layer
    output = keras.layers.Dense(1)(most_recent_layer)

    #Make Model
    model = keras.models.Model(inputs=[position_input, metadata_input],
                               outputs = output,
                               name = name_string)
    model.compile(optimizer = 'adam',
                  loss = loss_func,
                  metrics = [correctness_smooth, correctness_sharp])
    return model

# even_data = [positions_even, metadata_even, labels_even]
natural_data = [positions_natural, metadata_natural, labels_natural]

class GeneralModel:
    def __init__(self, name):
        self.name = name
        self.filters_list = []
        self.raw_nn_sizes = []
        self.pre_injection_nn_sizes = []
        self.primary_nn_sizes = []
        self.injection_type = "primaryNN"
        self.loss_func = exp_loss

    def add_raw_nn_layer(self, layer_size):
        self.raw_nn_sizes.append(layer_size)

    def add_pre_injection_nn_layer(self, layer_size):
        self.pre_injection_nn_sizes.append(layer_size)

    def add_primary_nn_layer(self, layer_size):
        self.primary_nn_sizes.append(layer_size)

    def add_convolutional_filter(self, quantity, shape):
        self.filters_list.append((quantity, shape))

    def inject_metadata_at_raw(self):
        self.injection_type = "rawNN"

    def set_loss_function(self, loss_function):
        self.loss_func = loss_function

    def show_summary(self):
        self.model.summary()

    def pre_generation_checks(self):
        pass

    def generate_model(self):
        self.pre_generation_checks()
        self.model = make_model(name_string = self.name,
                           convolution_list = self.filters_list,
                           raw_position_nn = self.raw_nn_sizes,
                           pre_injection_nn = self.pre_injection_nn_sizes,
                           primary_nn = self.primary_nn_sizes,
                           metadata_injection = self.injection_type,
                           loss_func = self.loss_func)

    def make_clone_ungenerated(self, name):
        g = GeneralModel(name)
        g.filters_list = self.filters_list
        g.raw_nn_sizes = self.raw_nn_sizes
        g.pre_injection_nn_sizes = self.pre_injection_nn_sizes
        g.primary_nn_sizes = self.primary_nn_sizes
        g.injection_type = self.injection_type
        g.loss_func = self.loss_func
        return g

    def get_model(self):
        return self.model

    def fit(self, data, epochs = 5, split_ratio = 0.2):
        print(self.name)
        return self.model.fit(x = [data[0], data[1]], y = data[2], epochs=epochs, validation_split = split_ratio)

model = GeneralModel("without_raw")
#add components based on diagram linked in shared drive

#add to convolutional part of model
# model.add_convolutional_filter(1, (8,8))

model.add_convolutional_filter(50, (3,3))
model.add_convolutional_filter(100, (5,5))

model.add_convolutional_filter(20, (8,3))
model.add_convolutional_filter(20, (3,8))

# model.add_convolutional_filter(20, (7,7))
# model.add_convolutional_filter(20, (4,4))
# model.add_convolutional_filter(20, (5,2))
# model.add_convolutional_filter(20, (2,5))
# model.add_convolutional_filter(20, (2,2))

#add primary neural network layers
model.add_primary_nn_layer(50)
model.add_primary_nn_layer(300)
model.add_primary_nn_layer(30)

# model.inject_metadata_at_raw()
model.set_loss_function(sig_loss)
#show structure:

#generate the model
model.generate_model()
# model.show_summary()



#see natural ratio
white_total, black_total, draw_total, total = get_ratios(labels_natural)
print("natural data result ratios:\n\t white wins: {}       black wins: {}      draw: {}".format(white_total/total, black_total/total, draw_total/total))
print(np.shape(positions_natural))

history_model_natural = model.fit(data = natural_data, epochs = 15)



# model2
model2 = model.make_clone_ungenerated("with_raw")
model2.add_raw_nn_layer(128)
model2.add_raw_nn_layer(50)
model2.add_raw_nn_layer(20)
model2.generate_model()
# model2.show_summary()

history_model_with_raw = model2.fit(data = natural_data, epochs = 15)